FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=19 4 5 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (19, 5, 5.00000000000000000000e-01) (19, 5, 5.00000000000000000000e-01) (19, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 8.32564353942871093750e-01) (1, -5.41527509689331054688e+00) (2, 1.19908499717712402344e+00) (3, -2.81293559074401855469e+00) (4, 3.19572508335113525391e-01) (5, -5.94241311773657798767e-03) (6, 5.07578849792480468750e-01) (7, -4.79234504699707031250e+01) (8, -2.05508232116699218750e-01) (9, -1.30484247207641601562e+01) (10, -1.74724578857421875000e+01) (11, 5.60265922546386718750e+00) (12, 7.44857025146484375000e+00) (13, 3.84046983718872070312e+00) (14, 6.45947515964508056641e-01) (15, 5.44512414932250976562e+00) (16, 9.58487018942832946777e-02) (17, -1.41894721984863281250e+00) (18, 3.63107174634933471680e-02) (0, -2.33971652984619140625e+01) (1, -5.69889945983886718750e+01) (2, -1.00684585571289062500e+01) (3, 2.34250812530517578125e+01) (4, -1.02099189758300781250e+01) (5, -2.49078044891357421875e+01) (6, -1.03525657653808593750e+01) (7, 1.02351045608520507812e+01) (8, -1.01826181411743164062e+01) (9, 1.08530654907226562500e+01) (10, -9.96652889251708984375e+00) (11, 5.21811771392822265625e+00) (12, -1.31000709533691406250e+00) (13, 5.80109634399414062500e+01) (14, -1.01557264328002929688e+01) (15, 2.64100151062011718750e+01) (16, -3.78435635566711425781e+00) (17, -2.49215354919433593750e+01) (18, -2.49025363922119140625e+01) (0, -1.73677891492843627930e-01) (1, -1.59622979164123535156e+00) (2, 8.20547401905059814453e-01) (3, -1.60855960845947265625e+01) (4, -4.40631248056888580322e-02) (5, -4.63486671447753906250e-01) (6, -5.69098651409149169922e-01) (7, -1.06991281509399414062e+01) (8, -6.05374157428741455078e-01) (9, 2.05069446563720703125e+00) (10, -8.54910850524902343750e-01) (11, -1.64363503456115722656e+00) (12, 2.24274997711181640625e+01) (13, -5.78623265027999877930e-02) (14, -5.12070894241333007812e-01) (15, 1.10525369644165039062e+00) (16, 1.35236816406250000000e+01) (17, -2.69963812828063964844e+00) (18, -6.93116247653961181641e-01) (19, -8.26444244384765625000e+00) (20, 3.47638273239135742188e+00) (21, 9.90551376342773437500e+00) (22, -2.17356514930725097656e+00) (19, -7.28842449188232421875e+00) (20, 4.73982286453247070312e+00) (21, -7.65515995025634765625e+00) (22, -2.51450371742248535156e+00) (19, 5.82658815383911132812e+00) (20, 2.68252825736999511719e+00) (21, -5.12296867370605468750e+00) (22, -2.00642466545104980469e+00) (19, 5.54814481735229492188e+00) (20, 4.38811922073364257812e+00) (21, 4.94349050521850585938e+00) (22, -1.29268097877502441406e+00) 
